# Machine Learning Engineer Nanodegree Capstone Proposal 

## Stock Price Prediction, A Deep Learning Approach

Jiaqi Liu

August 22, 2018

## Proposal

### Domain Background

The stock market is one of the most interesting financial systems. It attracts the attention of investors, economists, data engineers and machine learning scientists.[1][2] Certainly, gaining wealth in the stock market is the goal of most participants. However the stock market and the data generated by it are of great value to engineers and scientists in the machine learning field, since they provide a efficient metric to evaluate many machine learning / deep learning techniques. 

Therefore, in this capstone project of the Machine Learning Engineer Nanodegree, I would like to take part in the game, having the dream for both becoming wealthy in personal finance and proficient in machine learning application.


### Problem Statement
The basic principle in stock trading is that one should *buy low and sell high* to gain profit from it. The price of a stock changes every day and even within each day. And often we can easily obtain structured stock price files or record easily online. Most of these records contains the following data:

1. **Date** of each record item
1. **Open price** of that day
1. **High price** of that day
1. **Low price** of that day
1. **Close price** of that day

There might be other types of stock price data in a record depending on the source. *Close price* is of the most interest to us. Thus in this project we will focus on predicting the close price in the future. Having the prediction, we can compare it with the real target value to see how accurate the prediction is. Evaluation metrics will be described in a later section.

### Datasets and Inputs

The datasets that we will be using is the historical stock price records obtained from Yahoo Finance.[3] The records can be downloaded from the *Historical Data* tab under each stock or composite index. 

The downloaded stock prices record file is CSV-formatted, containing the following columns:

1. Date, time series, the date of the record item
1. Open, floating point numerical, the open price of that day
1. High, floating point numerical, the higt price of that day
1. Low, floating point numerical, the low price of that day
1. Close, floating point numerical, the close price of that day
1. Adj Close, floating point numerical, the adjusted close price of that day
1. Volume, integer numerical, the trading volume of that day

It is helpful to have a look at a concrete fragment example of the *SPDR S&P 500 ETF* (SPY) record file.[4] As we can see, the example table is composed of the 6 kinds of data we have just described. It contains the stock price record of each trading day from August 10 2018 to August 14 2018.

| Date      | Open        | High        | Low         | Close       | Adj Close   | Volume     | 
|-----------|-------------|-------------|-------------|-------------|-------------|------------| 
| 8/10/2018 | 2838.899902 | 2842.199951 | 2825.810059 | 2833.280029 | 2833.280029 | 3256040000 | 
| 8/13/2018 | 2835.459961 | 2843.399902 | 2819.879883 | 2821.929932 | 2821.929932 | 3158450000 | 
| 8/14/2018 | 2827.879883 | 2843.110107 | 2826.580078 | 2839.959961 | 2839.959961 | 2976970000 | 

In this project, we will focus on predicting the adjusted close price. To be more precisely, we will use the adjusted close price of preceding days to predict the adjusted close price of the next trading day.

### Solution Statement

In this project, we will build a model to predict the adjusted close price of the next trading day. The model is essentially a Recurrent Neural Network (RNN) with Long Short Term Memory (LSTM). RNN performs well on sequential data such as text and voice. The stock prices can also be represented as a sequence of data. That is the reason we have chosen RNN as the training model. 

To train the model, we feed a data sequence of a certain period. To evaluate the trained model, we input another data sequence of a different period and the model generates the predicted close price of the next trading day. The output of the model is quantifiable and measurable, since the predicted value can be compared with the real one in the dataset.

### Benchmark Model

The benchmark models that we will be using consists of two machine learning models: Linear Regression and Random Forest Regression.[5][6] 

To compare our RNN model with the benchmark models, we feed the same training data, input the same test set and evaluate their predictions with the same evaluation metrics, which will be described in the following section.

### Evaluation Metrics

To evaluate the predictions generated from the RNN model, we will use the root-mean-square deviation (RMSD) or root-mean-square error (RMSE).[7] The mathematical form of RMSD can be defined as the following formula: 

$$
{\displaystyle \operatorname {RMSD} ={\sqrt {\frac {\sum _{t=1}^{T}({\hat {y}}_{t}-y_{t})^{2}}{T}}}.}
$$

Here, $T$ is the size or length of the output data which consists of the predicted values. ${\hat {y}}_{t}$ is the $t$th prediction value and $y_{t}$ is the $t$ true target value.

### Project Design

#### Workflow Overview

The main workflow is illustrated as the flowchart below, followed by more detailed explanation in the next subsection.

```flow
st=>start: Start
dg=>operation: Data Gathering
dpp=>operation: Data Pre-processing
ds=>operation: Data Split
mt=>operation: Model Training
cond_opt=>condition: Finished Optimization?
opt=>operation: Model/Hyper-parameter Optimization
eval=>operation: Evaluation
comp=>operation: Benchmark Comparison
e=>end

st->dg->dpp->ds->mt->cond_opt
cond_opt(yes)->eval->comp->e
cond_opt(no)->opt->mt

```

#### More on the workflow

##### Data Gathering

The dataset is downloaded from Yahoo Finance[3]. The raw format is described as the table in the section of *Datasets and Inputs*.

##### Data Pre-processing

We need to refine the dataset before use it to fit and test the model. Possible pre-processing methods are: 

1. Drop unwanted columns
1. Verify missing data
1. Standardize time/date series
1. Normalize numerical values

##### Data Split

We need to split the dataset to the following subsets:

1. Training set, used to train the model
2. Validation set, used to detect overfitting and optimize model structure and hyper-parameters
3. Test set, used to evaluate the final results

##### Model Training and Optimization

In this phase, we first create an initial setup of the model then feed the training set to the model. Then we use the validation set to validate the model and tune the hyper-parameters if necessary.

##### Evaluation

After training and optimizing the model, we use the test set to see if the predicted stock prices is close to the true target values. Also, we use the evaluation metrics (RMSD) described in a previous section to give a subjective measurement of the model's performance:

$$
{\displaystyle \operatorname {RMSD} ={\sqrt {\frac {\sum _{t=1}^{T}({{predicted\_price}}_{t}-target\_price_{t})^{2}}{T}}}.}
$$

##### Benchmark Comparison

Since we have selected two benchmark models (Linear Regression and Random Forest Regression), we can use them to see how well our model behaves comparing to other models. We can compare them using both subjective RMSD metrics and plotted charts.

### References

[1]: W Huang, Y Nakamori, SY Wang (2005). Forecasting stock market movement direction with support vector machine
[2]: RR Trippi, E Turban (1992). Neural networks in finance and investing: Using artificial intelligence to improve real world performance
[3]: Yahoo Finance https://finance.yahoo.com
[4]: SPDR S&P 500 ETF (SPY) Historical Data  https://finance.yahoo.com/quote/SPY/history?p=SPY
[5]: J Neter, W Wasserman, MH Kutner (1989). Applied linear regression models
[6]: L Breiman (2001). Random Forests. Machine Learning. 45 (1): 5â€“32
[7]: Root-mean-square deviation https://en.wikipedia.org/wiki/Root-mean-square_deviation

